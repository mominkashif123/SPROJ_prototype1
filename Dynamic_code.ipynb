{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11391578,"sourceType":"datasetVersion","datasetId":7134075},{"sourceId":11392137,"sourceType":"datasetVersion","datasetId":7134494}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport joblib\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.compose import ColumnTransformer\n\n# Dictionary mapping question columns to CSV paths\nQUESTION_FILES = {\n    \"Q2_Topics\": \"/kaggle/input/paper1-dataset/Q2_prediction_dataset.csv\",\n    \"Q3_Topic\": \"/kaggle/input/paper1-dataset/Q3_prediction_dataset.csv\",\n    \"Q4_Topic\": \"/kaggle/input/paper1-dataset/Q4_prediction_dataset.csv\",\n    \"Q5_Topic\": \"/kaggle/input/paper1-dataset/Q5_prediction_complete.csv\"\n}\n\n# Store final predictions in a dictionary\nnext_year_predictions = {}\n\nfor question_col, csv_path in QUESTION_FILES.items():\n    print(f\"\\n========== Processing {question_col} ==========\")\n    \n    # 1. Load data specific to this question\n    df_question = pd.read_csv(csv_path)\n\n    # 2. Identify and remove rare classes\n    class_counts = df_question[question_col].value_counts()\n    rare_classes = class_counts[class_counts == 1].index\n    df_question = df_question[~df_question[question_col].isin(rare_classes)]\n\n    # Handle case where after removing rare classes, there's insufficient data\n    if df_question[question_col].nunique() < 2:\n        print(f\"Skipping {question_col} — not enough data/classes.\")\n        continue\n\n    # 3. Encode target\n    label_encoder = LabelEncoder()\n    df_question[question_col] = df_question[question_col].astype(str)\n    df_question[f\"{question_col}_encoded\"] = label_encoder.fit_transform(df_question[question_col])\n    \n    # 4. Prepare features (X) and target (y)\n    #    Adjust if your CSV columns are named differently\n    X = df_question[['Year', 'Paper_Session', 'Paper_Varient']]\n    y = df_question[f\"{question_col}_encoded\"]\n    \n    # One-hot encoding on Paper_Session\n    ct = ColumnTransformer(\n        [('onehot', OneHotEncoder(handle_unknown='ignore'), ['Paper_Session'])],\n        remainder='passthrough'\n    )\n    X_transformed = ct.fit_transform(X)\n\n    # 5. Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(\n        X_transformed, y, test_size=0.3, random_state=42, stratify=y\n    )\n\n    # 6. Model training\n    model = RandomForestClassifier(random_state=42)\n    model.fit(X_train, y_train)\n\n    # 7. Evaluation\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n\n    # 8. Predict for next year\n    next_year_data = pd.DataFrame({\n        'Year': [2025],\n        'Paper_Session': ['MJ'],\n        'Paper_Varient': ['12']\n    })\n    X_next_year = ct.transform(next_year_data)\n    predicted_topic_encoded = model.predict(X_next_year)\n    predicted_topic = label_encoder.inverse_transform(predicted_topic_encoded)\n    \n    next_year_predictions[question_col] = predicted_topic[0]\n    print(f\"Predicted Topic for 2025 ({question_col}): {predicted_topic[0]}\")\n\n    # 9. Save the pipeline objects\n    joblib.dump(model, f\"rf_model_{question_col}.pkl\")\n    joblib.dump(ct, f\"column_transformer_{question_col}.pkl\")\n    joblib.dump(label_encoder, f\"label_encoder_{question_col}.pkl\")\n\n# Print all predictions\nprint(\"\\n========== Final Next Year Predictions for All Questions ==========\")\nfor question, topic in next_year_predictions.items():\n    print(f\"{question} => {topic}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T18:28:30.131832Z","iopub.execute_input":"2025-04-13T18:28:30.132162Z","iopub.status.idle":"2025-04-13T18:28:30.902670Z","shell.execute_reply.started":"2025-04-13T18:28:30.132138Z","shell.execute_reply":"2025-04-13T18:28:30.901697Z"}},"outputs":[{"name":"stdout","text":"\n========== Processing Q2_Topics ==========\nPredicted Topic for 2025 (Q2_Topics): the account of the compilation of the Qur’an under the Rightly Guided Caliphs \n\n========== Processing Q3_Topic ==========\nPredicted Topic for 2025 (Q3_Topic): the importance of his actions as examples for Muslim individuals in their personal conduct and relations with others including women and non-Muslims\n\n========== Processing Q4_Topic ==========\nPredicted Topic for 2025 (Q4_Topic): the main events of his activities in Madina, his leadership of the community there and his conflicts with the Makkans and others\n\n========== Processing Q5_Topic ==========\nPredicted Topic for 2025 (Q5_Topic): his leading Companions, including the Ten Blessed Companions during his lifetime.\n\n========== Final Next Year Predictions for All Questions ==========\nQ2_Topics => the account of the compilation of the Qur’an under the Rightly Guided Caliphs \nQ3_Topic => the importance of his actions as examples for Muslim individuals in their personal conduct and relations with others including women and non-Muslims\nQ4_Topic => the main events of his activities in Madina, his leadership of the community there and his conflicts with the Makkans and others\nQ5_Topic => his leading Companions, including the Ten Blessed Companions during his lifetime.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install transformers datasets imbalanced-learn difflib2 --quiet\n\nimport pandas as pd\nimport joblib\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.compose import ColumnTransformer\n\nimport torch\nfrom torch.utils.data import Dataset\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n\n\n###########################################################\n# A) CLASSIFICATION (Random Forest) FOR MULTIPLE QUESTIONS\n###########################################################\n\n# Example CSV paths for classification\nCLASSIFICATION_FILES = {\n    \"Q2_Topics\": \"/kaggle/input/paper1-dataset/Q2_prediction_dataset.csv\",\n    \"Q3_Topic\": \"/kaggle/input/paper1-dataset/Q3_prediction_dataset.csv\",\n    \"Q4_Topic\": \"/kaggle/input/paper1-dataset/Q4_prediction_dataset.csv\",\n    \"Q5_Topic\": \"/kaggle/input/paper1-dataset/Q5_prediction_complete.csv\"\n}\n\n# Dictionary to store the final predicted topic for each question\nnext_year_predictions = {}\n\nfor question_col, csv_path in CLASSIFICATION_FILES.items():\n    print(f\"\\n========== CLASSIFICATION for {question_col} ==========\")\n    \n    df = pd.read_csv(csv_path)\n\n    # 1) Remove rare classes (appear only once)\n    class_counts = df[question_col].value_counts()\n    rare_classes = class_counts[class_counts == 1].index\n    df = df[~df[question_col].isin(rare_classes)]\n\n    if df[question_col].nunique() < 2:\n        print(f\"Skipping {question_col} — not enough classes after removing rare ones.\")\n        continue\n\n    # 2) Label encode the target\n    label_encoder = LabelEncoder()\n    df[question_col] = df[question_col].astype(str)\n    df[f\"{question_col}_encoded\"] = label_encoder.fit_transform(df[question_col])\n\n    # 3) ColumnTransformer for Paper_Session\n    ct = ColumnTransformer(\n        [('onehot', OneHotEncoder(handle_unknown='ignore'), ['Paper_Session'])],\n        remainder='passthrough'\n    )\n\n    X = df[['Year', 'Paper_Session', 'Paper_Varient']]\n    y = df[f\"{question_col}_encoded\"]\n    X_transformed = ct.fit_transform(X)\n\n    # 4) Train/Test split\n    X_train, X_test, y_train, y_test = train_test_split(\n        X_transformed, y, test_size=0.3, random_state=42, stratify=y\n    )\n\n    # 5) Train RandomForest\n    model = RandomForestClassifier(random_state=42)\n    model.fit(X_train, y_train)\n\n    # 6) Evaluate\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"Accuracy for {question_col}: {accuracy:.3f}\")\n    print(classification_report(y_test, y_pred, zero_division=0))\n\n    # 7) Predict next year's topic (2025)\n    next_year_data = pd.DataFrame({\n        'Year': [2025],\n        'Paper_Session': ['MJ'],\n        'Paper_Varient': ['12']\n    })\n    X_next_year = ct.transform(next_year_data)\n    predicted_topic_encoded = model.predict(X_next_year)\n    predicted_topic = label_encoder.inverse_transform(predicted_topic_encoded)\n    \n    # 8) Store the predicted topic\n    next_year_predictions[question_col] = predicted_topic[0]\n    print(f\"Predicted Topic for 2025 ({question_col}): {predicted_topic[0]}\")\n\n    # (Optional) Save the model pieces\n    joblib.dump(model, f\"rf_model_{question_col}.pkl\")\n    joblib.dump(ct, f\"column_transformer_{question_col}.pkl\")\n    joblib.dump(label_encoder, f\"label_encoder_{question_col}.pkl\")\n\n# Print out the final classification predictions\nprint(\"\\n========== Final Next Year Predictions for All Questions ==========\")\nfor question, topic in next_year_predictions.items():\n    print(f\"{question} => {topic}\")\n\n\n###########################################################\n# B) GPT-2 QUESTION GENERATION — ONE MODEL PER QUESTION\n###########################################################\n\n# Example CSV paths for GPT-2 (adjust to your actual GPT-2 data)\nGENERATION_FILES = {\n    \"Q2_Topics\": \"/kaggle/input/generation-dataset/Q2_complete_dataset.csv\",\n    \"Q3_Topic\": \"/kaggle/input/generation-dataset/Q3_dataset_complete.csv\",\n    \"Q4_Topic\": \"/kaggle/input/generation-dataset/Q4_dataset_complete.csv\",\n    \"Q5_Topic\": \"/kaggle/input/generation-dataset/Q5_dataset_complete.csv\",\n}\n\nclass TopicQuestionDataset(Dataset):\n    def __init__(self, texts, tokenizer, max_length=128):\n        self.encodings = []\n        for txt in texts:\n            enc = tokenizer(\n                txt,\n                truncation=True,\n                max_length=max_length,\n                padding=\"max_length\"\n            )\n            self.encodings.append(enc)\n\n    def __len__(self):\n        return len(self.encodings)\n\n    def __getitem__(self, idx):\n        item = self.encodings[idx]\n        return {\n            \"input_ids\": torch.tensor(item[\"input_ids\"], dtype=torch.long),\n            \"attention_mask\": torch.tensor(item[\"attention_mask\"], dtype=torch.long)\n        }\n\ndef data_collator(batch):\n    input_ids = torch.stack([f[\"input_ids\"] for f in batch])\n    attention_mask = torch.stack([f[\"attention_mask\"] for f in batch])\n    labels = input_ids.clone()\n    return {\n        \"input_ids\": input_ids,\n        \"attention_mask\": attention_mask,\n        \"labels\": labels\n    }\n\nfinal_generated = []\n\nfor question_key, gen_csv_path in GENERATION_FILES.items():\n    print(f\"\\n========== GPT-2 Generation for {question_key} ==========\")\n\n    # 1) Load dataset for GPT-2 training\n    df_gen = pd.read_csv(gen_csv_path)\n\n    # e.g. \"Q2_Topics\" => topic_col, \"Q2\" => question_col\n    topic_col = question_key\n    question_col = question_key.replace(\"_Topics\", \"\")  # e.g. \"Q2_Topics\" => \"Q2\"\n\n    df_gen = df_gen.dropna(subset=[topic_col, question_col])\n\n    # 2) Prepare training text: \"Topic: ...\\nQuestion: ...\\n<|endoftext|>\"\n    train_texts = []\n    for _, row in df_gen.iterrows():\n        t_str = str(row[topic_col]).strip()\n        q_str = str(row[question_col]).strip()\n        combined = f\"Topic: {t_str}\\nQuestion: {q_str}\\n<|endoftext|>\"\n        train_texts.append(combined)\n\n    # 3) Initialize GPT-2 from scratch for this question\n    model_name = \"gpt2\"  # or \"distilgpt2\"\n    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n    model = GPT2LMHeadModel.from_pretrained(model_name)\n\n    # Fix the pad token\n    tokenizer.pad_token = tokenizer.eos_token\n    model.config.pad_token_id = model.config.eos_token_id\n\n    # Create dataset & trainer\n    train_dataset = TopicQuestionDataset(train_texts, tokenizer, max_length=500)\n\n    training_args = TrainingArguments(\n        output_dir=f\"./temp-output-{question_key}\",\n        overwrite_output_dir=True,\n        num_train_epochs=20,   # adjust as needed\n        per_device_train_batch_size=2,\n        logging_steps=5,\n        logging_strategy=\"steps\",\n        save_strategy=\"no\",\n        report_to=[]\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        data_collator=data_collator\n    )\n\n    # 4) Train GPT-2 on this question's data only\n    trainer.train()\n    print(f\"Finished GPT-2 training for {question_key}.\")\n\n    # 5) Save the model (optional)\n    model_save_path = f\"./fine-tuned-gpt2-{question_key}\"\n    model.save_pretrained(model_save_path)\n    tokenizer.save_pretrained(model_save_path)\n\n    # 6) Generate a question for the predicted topic (from Random Forest)\n    #    No fallback, no uniqueness checks\n    predicted_topic_for_this_key = next_year_predictions[question_key]\n\n    def generate_question_for_topic(topic, max_length=500, temperature=0.7, top_p=0.9):\n        prompt = f\"Topic: {topic}\\nQuestion:\"\n        input_ids = tokenizer.encode(prompt, return_tensors='pt').to(model.device)\n        output = model.generate(\n            input_ids=input_ids,\n            max_length=max_length,\n            temperature=temperature,\n            top_p=top_p,\n            do_sample=True,\n            num_return_sequences=1\n        )\n        text = tokenizer.decode(output[0], skip_special_tokens=True)\n        if \"Question:\" in text:\n            splitted = text.split(\"Question:\")\n            return splitted[-1].strip()\n        return text.strip()\n\n    final_question = generate_question_for_topic(predicted_topic_for_this_key)\n\n    print(f\"--- Predicted Topic (RF) for {question_key}: {predicted_topic_for_this_key}\")\n    print(f\"--- Generated Question: {final_question}\")\n\n    final_generated.append({\n        \"question_key\": question_key,\n        \"predicted_topic\": predicted_topic_for_this_key,\n        \"generated_question\": final_question\n    })\n\n########################################\n# PART C: PRINT ALL GENERATED QUESTIONS\n########################################\nprint(\"\\n========== ALL GENERATED QUESTIONS ==========\")\nfor item in final_generated:\n    print(f\"Question Key: {item['question_key']}\")\n    print(f\"  Predicted Topic: {item['predicted_topic']}\")\n    print(f\"  Generated Question: {item['generated_question']}\")\n    print(\"--------------------------------\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T18:40:47.851784Z","iopub.execute_input":"2025-04-13T18:40:47.852099Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: Could not find a version that satisfies the requirement difflib2 (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for difflib2\u001b[0m\u001b[31m\n\u001b[0m\n========== CLASSIFICATION for Q2_Topics ==========\nAccuracy for Q2_Topics: 0.400\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         1\n           1       0.50      0.50      0.50         2\n           2       0.50      1.00      0.67         1\n           3       0.00      0.00      0.00         1\n\n    accuracy                           0.40         5\n   macro avg       0.25      0.38      0.29         5\nweighted avg       0.30      0.40      0.33         5\n\nPredicted Topic for 2025 (Q2_Topics): the account of the compilation of the Qur’an under the Rightly Guided Caliphs \n\n========== CLASSIFICATION for Q3_Topic ==========\nAccuracy for Q3_Topic: 0.167\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         4\n           1       0.00      0.00      0.00         1\n           2       0.00      0.00      0.00         3\n           3       0.00      0.00      0.00         0\n           4       0.25      0.25      0.25         4\n           5       0.29      0.50      0.36         4\n           6       0.00      0.00      0.00         2\n\n    accuracy                           0.17        18\n   macro avg       0.08      0.11      0.09        18\nweighted avg       0.12      0.17      0.14        18\n\nPredicted Topic for 2025 (Q3_Topic): the importance of his actions as examples for Muslim individuals in their personal conduct and relations with others including women and non-Muslims\n\n========== CLASSIFICATION for Q4_Topic ==========\nAccuracy for Q4_Topic: 0.167\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         1\n           1       0.00      0.00      0.00         0\n           2       0.00      0.00      0.00         1\n           3       0.29      0.40      0.33         5\n           4       0.00      0.00      0.00         1\n           5       0.00      0.00      0.00         1\n           6       0.33      0.33      0.33         3\n           7       0.00      0.00      0.00         3\n           8       0.00      0.00      0.00         1\n           9       0.00      0.00      0.00         2\n\n    accuracy                           0.17        18\n   macro avg       0.06      0.07      0.07        18\nweighted avg       0.13      0.17      0.15        18\n\nPredicted Topic for 2025 (Q4_Topic): the main events of his activities in Madina, his leadership of the community there and his conflicts with the Makkans and others\n\n========== CLASSIFICATION for Q5_Topic ==========\nAccuracy for Q5_Topic: 0.133\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         2\n           1       0.00      0.00      0.00         1\n           2       0.33      0.33      0.33         3\n           3       0.00      0.00      0.00         3\n           4       0.00      0.00      0.00         1\n           5       0.00      0.00      0.00         1\n           6       0.33      0.25      0.29         4\n\n    accuracy                           0.13        15\n   macro avg       0.10      0.08      0.09        15\nweighted avg       0.16      0.13      0.14        15\n\nPredicted Topic for 2025 (Q5_Topic): his leading Companions, including the Ten Blessed Companions during his lifetime.\n\n========== Final Next Year Predictions for All Questions ==========\nQ2_Topics => the account of the compilation of the Qur’an under the Rightly Guided Caliphs \nQ3_Topic => the importance of his actions as examples for Muslim individuals in their personal conduct and relations with others including women and non-Muslims\nQ4_Topic => the main events of his activities in Madina, his leadership of the community there and his conflicts with the Makkans and others\nQ5_Topic => his leading Companions, including the Ten Blessed Companions during his lifetime.\n\n========== GPT-2 Generation for Q2_Topics ==========\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61d2d5694e0b4c71817eba781af0ecb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eeb9b99a4798479888dd990219d3186f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea5f68702b6947a3a28ff7b9e22a3dd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c03dcb598a1d49fa984c771d581471c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f2520a3461d4aceb8cc010d602dff01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3a4b792bfba43faa8f1c7c2fb32d660"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4dd635d0b5a4a1f9eb1bc73d0b386bf"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [260/260 01:48, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>5</td>\n      <td>4.848600</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.608700</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.515500</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.376600</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.308400</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.217000</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.243800</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.213700</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.160500</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.177700</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>0.135100</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.137000</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.157200</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.116900</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.113300</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.122300</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.095500</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.089500</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.098500</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.088700</td>\n    </tr>\n    <tr>\n      <td>105</td>\n      <td>0.099400</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.068200</td>\n    </tr>\n    <tr>\n      <td>115</td>\n      <td>0.083200</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.073300</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>0.071100</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.066600</td>\n    </tr>\n    <tr>\n      <td>135</td>\n      <td>0.060700</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.067400</td>\n    </tr>\n    <tr>\n      <td>145</td>\n      <td>0.062000</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.059900</td>\n    </tr>\n    <tr>\n      <td>155</td>\n      <td>0.054500</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.049000</td>\n    </tr>\n    <tr>\n      <td>165</td>\n      <td>0.049200</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.048700</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>0.043100</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.054200</td>\n    </tr>\n    <tr>\n      <td>185</td>\n      <td>0.049000</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.047900</td>\n    </tr>\n    <tr>\n      <td>195</td>\n      <td>0.037800</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.043700</td>\n    </tr>\n    <tr>\n      <td>205</td>\n      <td>0.037800</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.043300</td>\n    </tr>\n    <tr>\n      <td>215</td>\n      <td>0.040400</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.038700</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>0.039600</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.041200</td>\n    </tr>\n    <tr>\n      <td>235</td>\n      <td>0.033200</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.040600</td>\n    </tr>\n    <tr>\n      <td>245</td>\n      <td>0.038800</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.033100</td>\n    </tr>\n    <tr>\n      <td>255</td>\n      <td>0.037800</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.036700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Finished GPT-2 training for Q2_Topics.\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"name":"stdout","text":"--- Predicted Topic (RF) for Q2_Topics: the account of the compilation of the Qur’an under the Rightly Guided Caliphs \n--- Generated Question: (a) Write about the ways in which Abu ’ ’Umar was involved in the compilation and preservation of the Qur’an.  (b) ‘The Qur’an is not preserved in written form because it is not preserved in writing.’ Agree or disagree with this statement, giving reasons for your answer.\n\n========== GPT-2 Generation for Q3_Topic ==========\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [300/300 02:13, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>5</td>\n      <td>5.231900</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.232700</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.157200</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.096700</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.036900</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.032600</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.020400</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.016500</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.015700</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.009500</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>0.010500</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.011100</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.006300</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.008400</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.007600</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.006800</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.008100</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.006300</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.008000</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.006300</td>\n    </tr>\n    <tr>\n      <td>105</td>\n      <td>0.008800</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.009700</td>\n    </tr>\n    <tr>\n      <td>115</td>\n      <td>0.005200</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.007800</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>0.005500</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.009900</td>\n    </tr>\n    <tr>\n      <td>135</td>\n      <td>0.006600</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.007100</td>\n    </tr>\n    <tr>\n      <td>145</td>\n      <td>0.006000</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.005400</td>\n    </tr>\n    <tr>\n      <td>155</td>\n      <td>0.004600</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.005900</td>\n    </tr>\n    <tr>\n      <td>165</td>\n      <td>0.005800</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.005900</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>0.006400</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.004000</td>\n    </tr>\n    <tr>\n      <td>185</td>\n      <td>0.006200</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.005600</td>\n    </tr>\n    <tr>\n      <td>195</td>\n      <td>0.006300</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.004100</td>\n    </tr>\n    <tr>\n      <td>205</td>\n      <td>0.004300</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.007900</td>\n    </tr>\n    <tr>\n      <td>215</td>\n      <td>0.005700</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.005800</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>0.005200</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.004700</td>\n    </tr>\n    <tr>\n      <td>235</td>\n      <td>0.004200</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.006300</td>\n    </tr>\n    <tr>\n      <td>245</td>\n      <td>0.006600</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.004500</td>\n    </tr>\n    <tr>\n      <td>255</td>\n      <td>0.005400</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.006900</td>\n    </tr>\n    <tr>\n      <td>265</td>\n      <td>0.005000</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.006200</td>\n    </tr>\n    <tr>\n      <td>275</td>\n      <td>0.005100</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.004800</td>\n    </tr>\n    <tr>\n      <td>285</td>\n      <td>0.005900</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.006700</td>\n    </tr>\n    <tr>\n      <td>295</td>\n      <td>0.005800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.005900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Finished GPT-2 training for Q3_Topic.\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"--- Predicted Topic (RF) for Q3_Topic: the importance of his actions as examples for Muslim individuals in their personal conduct and relations with others including women and non-Muslims\n--- Generated Question: the importance of his actions as examples for Muslim individuals in their personal conduct and relations with others including women and non-Muslims\n\n========== GPT-2 Generation for Q4_Topic ==========\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='255' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [255/300 01:52 < 00:20, 2.24 it/s, Epoch 16.93/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>5</td>\n      <td>5.001400</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.249400</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.153000</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.087700</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.063400</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.052300</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.040800</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.024200</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.021000</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.010300</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>0.027900</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.015700</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.008400</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.012400</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.011400</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.006900</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.007900</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.012900</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.010200</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.007500</td>\n    </tr>\n    <tr>\n      <td>105</td>\n      <td>0.009700</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.010900</td>\n    </tr>\n    <tr>\n      <td>115</td>\n      <td>0.006000</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.010400</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>0.005600</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.010200</td>\n    </tr>\n    <tr>\n      <td>135</td>\n      <td>0.009300</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.007300</td>\n    </tr>\n    <tr>\n      <td>145</td>\n      <td>0.008900</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.006000</td>\n    </tr>\n    <tr>\n      <td>155</td>\n      <td>0.007200</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.008200</td>\n    </tr>\n    <tr>\n      <td>165</td>\n      <td>0.005200</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.006200</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>0.008000</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.005900</td>\n    </tr>\n    <tr>\n      <td>185</td>\n      <td>0.007200</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.008200</td>\n    </tr>\n    <tr>\n      <td>195</td>\n      <td>0.007400</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.004500</td>\n    </tr>\n    <tr>\n      <td>205</td>\n      <td>0.006600</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.008200</td>\n    </tr>\n    <tr>\n      <td>215</td>\n      <td>0.006800</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.006700</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>0.006900</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.005500</td>\n    </tr>\n    <tr>\n      <td>235</td>\n      <td>0.005600</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.008100</td>\n    </tr>\n    <tr>\n      <td>245</td>\n      <td>0.006900</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.006000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null}]}